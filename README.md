# Multi-Layer-Perceptron
Code for Mutli Layer Perceptron(MLP)

MultiLayer Perceptron is the initial or basic neural network. It consists of an Input layer, Output Layer and hidden layers whose number varies depending upon the use case. To design an MLP model one must choose the activation function and no.of hidden layers. The weight parameters are chosen randomly, optimization is done using backpropagation algorithm.

In my code I have created a Neuron Layer, Neural Network Class so it can be generalised to any no.of neuron layers and any no.of neurons per layer as per user requirement. The activation function which I used is ReLu(Rectified Linear Units), even this can be changed as per requirement. The train and test inputs I have taken is to test XOR function, this can be changed as per requirements.

The detailed explanation of :
(1) multi layer perceptron can be found here https://en.wikipedia.org/wiki/Multilayer_perceptron 
(2) back propagation algorithm can be found here http://neuralnetworksanddeeplearning.com/chap2.html
(3) different types of Activation function can be found here https://medium.com/towards-data-science/activation-functions-and-its-types-which-is-better-a9a5310cc8f

version of python used : Python2
Enjoy!


